{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce7e860",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('./..')\n",
    "\n",
    "import csv\n",
    "import pickle\n",
    "import Methods.totals as totals\n",
    "import Methods.analysis as analysis\n",
    "import Methods.common as common\n",
    "\n",
    "with open(\"sorted_all_dataset.pkl\", \"rb\") as f:\n",
    "    dataset_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f933cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Getting totals\n",
    "    Getting the final classification for every PR and calculating totals\n",
    "\"\"\"\n",
    "repos = 342\n",
    "for repo_file in range(0, repos):\n",
    "    variant1 = dataset_dict[repo_file]['source']\n",
    "    variant2 = dataset_dict[repo_file]['destination']\n",
    "    \n",
    "    print(variant1, '-', variant2)\n",
    "    \n",
    "    try:\n",
    "        all_results = common.readResults(repo_file, variant1)\n",
    "        \n",
    "        pr_class = totals.final_class(all_results[0])\n",
    "        all_counts = totals.count_all_classifications(pr_class)\n",
    "\n",
    "        with open('Repos_totals/'+ str(repo_file) + '_' + variant1.split('/')[0] + '_' + variant1.split('/')[1] + '_totals.pkl', 'wb') as f:\n",
    "            pickle.dump([pr_class, all_counts],f)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bfbe8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Plotting the distribution of classifications\n",
    "\"\"\"\n",
    "\n",
    "total_all = 0\n",
    "total_mo_all = 0\n",
    "total_ed_all = 0\n",
    "total_sp_all = 0\n",
    "total_na_all = 0\n",
    "\n",
    "all_results = []\n",
    "\n",
    "repos = 342\n",
    "for repo_file in range(0,repos):\n",
    "    try:\n",
    "        variant1 = dataset_dict[repo_file]['source']\n",
    "        variant2 = dataset_dict[repo_file]['destination']\n",
    "        variant1_prs = dataset_dict[repo_file]['pr'].split('/')\n",
    "\n",
    "        all_totals= totals.read_totals(repo_file, variant1)\n",
    "\n",
    "        total_NA = 0\n",
    "        total_ED = 0\n",
    "        total_MO = 0\n",
    "        total_CC = 0\n",
    "        total_SP= 0\n",
    "        total_NE = 0\n",
    "        total_ERROR = 0\n",
    "\n",
    "        for pr in all_totals[0]:\n",
    "            verdict = all_totals[0][pr]['class']\n",
    "            if verdict == 'ED':\n",
    "                total_ED += 1\n",
    "            elif verdict =='MO':\n",
    "                total_MO += 1\n",
    "            elif verdict == 'SP':\n",
    "                total_SP += 1\n",
    "            elif verdict == 'NA':\n",
    "                total_NA += 1\n",
    "            elif verdict == 'CC':\n",
    "                total_CC += 1\n",
    "            elif verdict =='NE':\n",
    "                total_NE += 1\n",
    "            elif verdict == 'ERROR':\n",
    "                total_ERROR += 1\n",
    "                \n",
    "            total_mid = total_MO+ total_ED + total_SP\n",
    "            total_all += total_mid\n",
    "            \n",
    "        total_total =len(variant1_prs)\n",
    "        \n",
    "        total_mo_all += total_MO\n",
    "        total_ed_all += total_ED\n",
    "        total_sp_all += total_SP\n",
    "        total_na_all += total_NA\n",
    "\n",
    "        totals_list = [total_MO, total_ED, total_SP, total_CC, total_NE, total_NA, total_ERROR]\n",
    "\n",
    "        analysis.all_class_bar(totals_list, repo_file, variant1, variant2, False)\n",
    "#         analysis.all_class_pie(totals_list, repo_file, variant1, variant2, False)\n",
    "\n",
    "        all_results.append([variant1, variant2, repo_file, total_MO, total_ED, total_SP, total_CC, total_NE, total_NA, total_ERROR])\n",
    "\n",
    "    except Exception as e:\n",
    "        print(variant1)\n",
    "        print(\"Exception: \", e, '\\n\\n')\n",
    "\n",
    "header = [\"variant1\", \"variant2\", \"repo_file\", \"total_MO\", \"total_ED\", \"total_SP\", \"total_CC\", \"total_NE\", \"total_NA\",\" total_ERROR\"]\n",
    "with open(\"results.csv\", \"w\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    # write the header\n",
    "    writer.writerow(header)\n",
    "\n",
    "    # write multiple rows\n",
    "    writer.writerows(all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e90afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MO = ',total_mo_all)\n",
    "print('ED = ',total_ed_all)\n",
    "print('SP = ',total_sp_all)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
